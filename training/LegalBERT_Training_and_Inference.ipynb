{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "42f72382",
   "metadata": {},
   "source": [
    "# Legal-BERT GDPR: Training, Evaluation, and Inference\n",
    "\n",
    "This notebook helps you:\n",
    "- Inspect the dataset\n",
    "- Train (or reuse an existing) Legal-BERT 3-way classifier\n",
    "- Evaluate and visualize results\n",
    "- Run quick inference examples\n",
    "\n",
    "Notes:\n",
    "- Make sure your virtual environment is active before running.\n",
    "- For RTX 50xx GPUs on Windows, we installed torch 2.9.0+cu128 earlier.\n",
    "- If you hit an fp16 scaler error (\"Attempting to unscale FP16 gradients\"), we disable fp16 by default here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fe114f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment check\n",
    "import sys, platform\n",
    "print('PYTHON:', sys.executable)\n",
    "print('VERSION:', platform.python_version())\n",
    "try:\n",
    "    import torch\n",
    "    print('TORCH:', torch.__version__, '| CUDA:', getattr(torch.version, 'cuda', None), '| CUDA_AVAILABLE:', torch.cuda.is_available())\n",
    "    if torch.cuda.is_available():\n",
    "        print('CUDA_DEVICE:', torch.cuda.get_device_name(0))\n",
    "except Exception as e:\n",
    "    print('Torch import error:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49355536",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "from pathlib import Path\n",
    "DATA_PATH = Path('training/gdpr_final_training_dataset.csv')\n",
    "MODEL_NAME = 'nlpaueb/legal-bert-base-uncased'\n",
    "OUTPUT_DIR = Path('training/models/legalbert_3way')\n",
    "EPOCHS = 4\n",
    "BATCH_SIZE = 8\n",
    "LR = 2e-5\n",
    "MAX_LENGTH = 256\n",
    "SEED = 42\n",
    "USE_FP16 = False  # disable to avoid GradScaler error observed\n",
    "\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "print('DATA_PATH=', DATA_PATH.resolve())\n",
    "print('OUTPUT_DIR=', OUTPUT_DIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e1b2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset summary\n",
    "import json\n",
    "import pandas as pd\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print('Rows:', len(df))\n",
    "print('Columns:', list(df.columns))\n",
    "print('Label counts:', df['label'].value_counts().to_dict())\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61aa36bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers: split, metrics, plotting\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "CANONICAL_LABELS = ['compliant', 'ambiguous', 'non_compliant']\n",
    "LABEL2ID = {l: i for i, l in enumerate(CANONICAL_LABELS)}\n",
    "ID2LABEL = {i: l for l, i in LABEL2ID.items()}\n",
    "\n",
    "def normalize_labels(s):\n",
    "    def norm(x):\n",
    "        x = str(x).strip().lower().replace('-', '_').replace(' ', '_')\n",
    "        if x in CANONICAL_LABELS:\n",
    "            return x\n",
    "        return {'compliance':'compliant','noncompliant':'non_compliant','non_compliance':'non_compliant','unclear':'ambiguous','unknown':'ambiguous'}.get(x, 'ambiguous')\n",
    "    return s.map(norm)\n",
    "\n",
    "df['label'] = normalize_labels(df['label'])\n",
    "\n",
    "def stratified_split(df, seed=42):\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=seed)\n",
    "    y = df['label'].map(LABEL2ID)\n",
    "    train_idx, temp_idx = next(splitter.split(df, y))\n",
    "    train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "    temp_df = df.iloc[temp_idx].reset_index(drop=True)\n",
    "    splitter2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=seed)\n",
    "    y_temp = temp_df['label'].map(LABEL2ID)\n",
    "    dev_idx, test_idx = next(splitter2.split(temp_df, y_temp))\n",
    "    return (train_df.iloc[dev_idx].reset_index(drop=True),\n",
    "            train_df.iloc[test_idx].reset_index(drop=True)) if False else (\n",
    "            train_df, temp_df.iloc[dev_idx].reset_index(drop=True), temp_df.iloc[test_idx].reset_index(drop=True))\n",
    "\n",
    "def plot_confusion(cm, labels):\n",
    "    plt.figure(figsize=(4,3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "    plt.ylabel('True')\n",
    "    plt.xlabel('Pred')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3da38e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train (if needed) or load existing model\n",
    "import random\n",
    "import torch\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification,\n",
    "                          DataCollatorWithPadding, Trainer, TrainingArguments)\n",
    "from transformers.trainer_utils import set_seed\n",
    "\n",
    "set_seed(SEED); random.seed(SEED); np.random.seed(SEED)\n",
    "train_df, dev_df, test_df = stratified_split(df, seed=SEED)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "\n",
    "def encode(texts, max_length):\n",
    "    return tokenizer(texts, truncation=True, max_length=max_length, padding=False)\n",
    "\n",
    "train_enc = encode(train_df['text'].tolist(), MAX_LENGTH)\n",
    "dev_enc = encode(dev_df['text'].tolist(), MAX_LENGTH)\n",
    "test_enc = encode(test_df['text'].tolist(), MAX_LENGTH)\n",
    "\n",
    "class EncodedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, enc, labels):\n",
    "        self.enc = enc\n",
    "        self.labels = labels\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    def __getitem__(self, idx):\n",
    "        item = {k: self.enc[k][idx] for k in self.enc}\n",
    "        item['labels'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "y_train = train_df['label'].map(LABEL2ID).tolist()\n",
    "y_dev = dev_df['label'].map(LABEL2ID).tolist()\n",
    "y_test = test_df['label'].map(LABEL2ID).tolist()\n",
    "\n",
    "train_ds = EncodedDataset(train_enc, y_train)\n",
    "dev_ds = EncodedDataset(dev_enc, y_dev)\n",
    "test_ds = EncodedDataset(test_enc, y_test)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    preds = np.argmax(logits, axis=-1)\n",
    "    rep = classification_report(labels, preds, target_names=CANONICAL_LABELS, output_dict=True, zero_division=0)\n",
    "    out = {\n",
    "        'accuracy': float(rep.get('accuracy', 0.0)),\n",
    "        'f1_macro': float(rep['macro avg']['f1-score']),\n",
    "    }\n",
    "    return out\n",
    "\n",
    "if (OUTPUT_DIR / 'model.safetensors').exists():\n",
    "    print('Model exists. Loading from', OUTPUT_DIR)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(str(OUTPUT_DIR))\n",
    "else:\n",
    "    print('Training new model...')\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        MODEL_NAME, num_labels=len(CANONICAL_LABELS), id2label=ID2LABEL, label2id=LABEL2ID\n",
    "    )\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir=str(OUTPUT_DIR / 'checkpoints'),\n",
    "        num_train_epochs=EPOCHS,\n",
    "        per_device_train_batch_size=BATCH_SIZE,\n",
    "        per_device_eval_batch_size=max(8, BATCH_SIZE),\n",
    "        learning_rate=LR,\n",
    "        eval_strategy='epoch',\n",
    "        save_strategy='epoch',\n",
    "        load_best_model_at_end=True,\n",
    "        metric_for_best_model='f1_macro',\n",
    "        greater_is_better=True,\n",
    "        fp16=False,\n",
    "        logging_steps=50,\n",
    "        report_to=[],\n",
    "        seed=SEED,\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_ds,\n",
    "        eval_dataset=dev_ds,\n",
    "        data_collator=DataCollatorWithPadding(tokenizer),\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "    trainer.train()\n",
    "    trainer.save_model(str(OUTPUT_DIR))\n",
    "    tokenizer.save_pretrained(str(OUTPUT_DIR))\n",
    "    # test set prediction and saving minimal artifacts\n",
    "    preds = trainer.predict(test_ds)\n",
    "    y_pred = np.argmax(preds.predictions, axis=-1)\n",
    "    rep = classification_report(y_test, y_pred, target_names=CANONICAL_LABELS, output_dict=True, zero_division=0)\n",
    "    with open(OUTPUT_DIR / 'eval_report.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(rep, f, indent=2)\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=list(range(len(CANONICAL_LABELS))))\n",
    "    import pandas as pd\n",
    "    pd.DataFrame(cm, index=CANONICAL_LABELS, columns=CANONICAL_LABELS).to_csv(OUTPUT_DIR / 'confusion_matrix.csv')\n",
    "\n",
    "print('Ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e58f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate (uses saved artifacts if they exist)\n",
    "from pathlib import Path\n",
    "import json\n",
    "rep_path = OUTPUT_DIR / 'eval_report.json'\n",
    "if rep_path.exists():\n",
    "    rep = json.load(open(rep_path, 'r'))\n",
    "    from pprint import pprint\n",
    "    pprint({'accuracy': rep.get('accuracy'), 'macro_f1': rep.get('macro avg',{}).get('f1-score')})\n",
    "else:\n",
    "    print('No eval_report.json found. Rerun training cell to create.')\n",
    "\n",
    "# Show confusion matrix if present\n",
    "cm_path = OUTPUT_DIR / 'confusion_matrix.csv'\n",
    "if cm_path.exists():\n",
    "    import pandas as pd\n",
    "    cm_df = pd.read_csv(cm_path, index_col=0)\n",
    "    plot_confusion(cm_df.values, cm_df.columns.tolist())\n",
    "else:\n",
    "    print('No confusion_matrix.csv found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189c5784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference helper\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch, numpy as np\n",
    "\n",
    "inf_tokenizer = AutoTokenizer.from_pretrained(str(OUTPUT_DIR)) if (OUTPUT_DIR / 'tokenizer.json').exists() else tokenizer\n",
    "inf_model = AutoModelForSequenceClassification.from_pretrained(str(OUTPUT_DIR)).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def infer(text):\n",
    "    enc = inf_tokenizer([text], truncation=True, max_length=MAX_LENGTH, return_tensors='pt').to(inf_model.device)\n",
    "    with torch.no_grad():\n",
    "        logits = inf_model(**enc).logits.squeeze(0).cpu().numpy()\n",
    "    probs = np.exp(logits) / np.exp(logits).sum()\n",
    "    idx = int(np.argmax(probs))\n",
    "    scores = {CANONICAL_LABELS[i]: float(probs[i]) for i in range(len(CANONICAL_LABELS))}\n",
    "    return {'label': CANONICAL_LABELS[idx], 'confidence': float(probs[idx]), 'scores': scores, 'device': str(inf_model.device)}\n",
    "\n",
    "infer('We collect your data only with explicit consent and provide an easy opt-out at any time.')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
